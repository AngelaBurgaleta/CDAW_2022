{"cells":[{"cell_type":"markdown","metadata":{"id":"4J02i0Zx5o-o"},"source":["![](images/EscUpmPolit_p.gif \"UPM\")"]},{"cell_type":"markdown","metadata":{"id":"finhkCxc5o-s"},"source":["# Course Notes for Learning Intelligent Systems"]},{"cell_type":"markdown","metadata":{"id":"vsVC7rvv5o-t"},"source":["Department of Telematic Engineering Systems, Universidad Politécnica de Madrid, © Carlos A. Iglesias"]},{"cell_type":"markdown","metadata":{"id":"u-8bYBFW5o-t"},"source":["# Semantic Models"]},{"cell_type":"markdown","metadata":{"id":"TH2Kc1vd5o-t"},"source":["# Table of Contents\n","* [Objectives](#Objectives)\n","* [Corpus](#Corpus)\n","* [Converting Scikit-learn to gensim](#Converting-Scikit-learn-to-gensim)\n","* [Latent Dirichlet Allocation (LDA)](#Latent-Dirichlet-Allocation-%28LDA%29)\n","* [Latent Semantic Indexing (LSI)](#Latent-Semantic-Indexing-%28LSI%29)"]},{"cell_type":"markdown","metadata":{"id":"ZFXNgPA-5o-u"},"source":["# Objectives"]},{"cell_type":"markdown","metadata":{"id":"Zi6OGckU5o-u"},"source":["In this session we provide a quick overview of the semantic models presented during the classes. In this case, we will use a real corpus so that we can extract meaningful patterns.\n","\n","The main objectives of this session are:\n","* Understand the models and their differences\n","* Learn to use some of the most popular NLP libraries"]},{"cell_type":"markdown","metadata":{"id":"6ijS2OPy5o-v"},"source":["# Corpus"]},{"cell_type":"markdown","metadata":{"id":"HH7aOi-l5o-v"},"source":["We are going to use on of the corpus that come prepackaged with Scikit-learn: the [20 newsgroup datase](http://qwone.com/~jason/20Newsgroups/). The 20  newsgroup dataset contains 20k documents that belong to 20 topics.\n","\n","We inspect now the corpus using the facilities from Scikit-learn, as explain in [scikit-learn](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html#newsgroups)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4lu--mN5o-w","executionInfo":{"status":"ok","timestamp":1652017271320,"user_tz":-120,"elapsed":22734,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"c81ed7a3-09ab-4511-e3ea-6847c93d7182"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 2807)"]},"metadata":{},"execution_count":1}],"source":["from sklearn.datasets import fetch_20newsgroups\n","\n","# We filter only some categories, otherwise we have 20 categories\n","categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n","# We remove metadata to avoid bias in the classification\n","newsgroups_train = fetch_20newsgroups(subset='train', \n","                                      remove=('headers', 'footers', 'quotes'), \n","                                      categories=categories)\n","newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),\n","                                    categories=categories)\n","\n","\n","# Obtain a vector\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', min_df=10)\n","\n","vectors_train = vectorizer.fit_transform(newsgroups_train.data)\n","vectors_train.shape"]},{"cell_type":"markdown","metadata":{"id":"EG7-Tvzl5o-y"},"source":["# Converting Scikit-learn to gensim"]},{"cell_type":"markdown","metadata":{"id":"Rw31xo5h5o-y"},"source":["Although scikit-learn provides an LDA implementation, it is more popular the package *gensim*, which also provides an LSI implementation, as well as other functionalities. Fortunately, scikit-learn sparse matrices can be used in Gensim using the function *matutils.Sparse2Corpus()*. Anyway, if you are using intensively LDA,it can be convenient to create the corpus with their functions.\n","\n","You should install first:\n","\n","* *gensim*. Run 'conda install gensim' in a terminal.\n","* *python-Levenshtein*. Run 'conda install python-Levenshtein' in a terminal"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AoCchfs5o-z","executionInfo":{"status":"ok","timestamp":1652017271866,"user_tz":-120,"elapsed":553,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"48aa76b5-761d-4e7f-f86d-2901757c107d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["from gensim import matutils\n","\n","vocab = vectorizer.get_feature_names()\n","\n","dictionary = dict([(i, s) for i, s in enumerate(vectorizer.get_feature_names())])\n","corpus_tfidf = matutils.Sparse2Corpus(vectors_train)"]},{"cell_type":"markdown","metadata":{"id":"-6rlBGRq5o-z"},"source":["# Latent Dirichlet Allocation (LDA)"]},{"cell_type":"markdown","metadata":{"id":"V0gj70Du5o-0"},"source":["Although scikit-learn provides an LDA implementation, it is more popular the package *gensim*, which also provides an LSI implementation, as well as other functionalities. Fortunately, scikit-learn sparse matrices can be used in Gensim using the function *matutils.Sparse2Corpus()*."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ocSF2ZkK5o-0","executionInfo":{"status":"ok","timestamp":1652017494886,"user_tz":-120,"elapsed":18712,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}}},"outputs":[],"source":["from gensim.models.ldamodel import LdaModel\n","\n","# It takes a long time\n","\n","#  train the lda model, choosing number of topics equal to 4\n","lda = LdaModel(corpus_tfidf, num_topics=4, passes=20, id2word=dictionary)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2fOr3I35o-0","executionInfo":{"status":"ok","timestamp":1652017499173,"user_tz":-120,"elapsed":320,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"6b26de14-01db-4782-99af-6421b625c69d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0,\n","  '0.003*\"activity\" + 0.002*\"color\" + 0.002*\"complex\" + 0.002*\"netters\" + 0.002*\"objects\" + 0.002*\"eyes\" + 0.002*\"direct\" + 0.002*\"license\" + 0.002*\"apple\" + 0.002*\"missions\"'),\n"," (1,\n","  '0.003*\"aware\" + 0.003*\"objects\" + 0.003*\"brian\" + 0.003*\"claiming\" + 0.003*\"pain\" + 0.003*\"men\" + 0.003*\"obtained\" + 0.003*\"guns\" + 0.003*\"id\" + 0.003*\"company\"'),\n"," (2,\n","  '0.005*\"allow\" + 0.005*\"discuss\" + 0.005*\"certain\" + 0.004*\"member\" + 0.004*\"pounds\" + 0.004*\"compared\" + 0.004*\"greater\" + 0.004*\"fuel\" + 0.004*\"manipulation\" + 0.003*\"edited\"'),\n"," (3,\n","  '0.003*\"forces\" + 0.003*\"profit\" + 0.003*\"frank\" + 0.003*\"platform\" + 0.003*\"led\" + 0.003*\"friends\" + 0.003*\"president\" + 0.002*\"determine\" + 0.002*\"mechanism\" + 0.002*\"301\"')]"]},"metadata":{},"execution_count":4}],"source":["# check the topics\n","lda.print_topics(4)"]},{"cell_type":"code","source":["import nltk\n","nltk.download()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Z2BfBHT6tE3","executionInfo":{"status":"ok","timestamp":1652017552747,"user_tz":-120,"elapsed":18426,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"c30053e0-c296-4dd4-9775-f95c3a60f747"},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":["NLTK Downloader\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> d\n","\n","Download which package (l=list; x=cancel)?\n","  Identifier> book\n","    Downloading collection 'book'\n","       | \n","       | Downloading package abc to /root/nltk_data...\n","       |   Unzipping corpora/abc.zip.\n","       | Downloading package brown to /root/nltk_data...\n","       |   Unzipping corpora/brown.zip.\n","       | Downloading package chat80 to /root/nltk_data...\n","       |   Unzipping corpora/chat80.zip.\n","       | Downloading package cmudict to /root/nltk_data...\n","       |   Unzipping corpora/cmudict.zip.\n","       | Downloading package conll2000 to /root/nltk_data...\n","       |   Unzipping corpora/conll2000.zip.\n","       | Downloading package conll2002 to /root/nltk_data...\n","       |   Unzipping corpora/conll2002.zip.\n","       | Downloading package dependency_treebank to /root/nltk_data...\n","       |   Unzipping corpora/dependency_treebank.zip.\n","       | Downloading package genesis to /root/nltk_data...\n","       |   Unzipping corpora/genesis.zip.\n","       | Downloading package gutenberg to /root/nltk_data...\n","       |   Unzipping corpora/gutenberg.zip.\n","       | Downloading package ieer to /root/nltk_data...\n","       |   Unzipping corpora/ieer.zip.\n","       | Downloading package inaugural to /root/nltk_data...\n","       |   Unzipping corpora/inaugural.zip.\n","       | Downloading package movie_reviews to /root/nltk_data...\n","       |   Unzipping corpora/movie_reviews.zip.\n","       | Downloading package nps_chat to /root/nltk_data...\n","       |   Unzipping corpora/nps_chat.zip.\n","       | Downloading package names to /root/nltk_data...\n","       |   Unzipping corpora/names.zip.\n","       | Downloading package ppattach to /root/nltk_data...\n","       |   Unzipping corpora/ppattach.zip.\n","       | Downloading package reuters to /root/nltk_data...\n","       | Downloading package senseval to /root/nltk_data...\n","       |   Unzipping corpora/senseval.zip.\n","       | Downloading package state_union to /root/nltk_data...\n","       |   Unzipping corpora/state_union.zip.\n","       | Downloading package stopwords to /root/nltk_data...\n","       |   Unzipping corpora/stopwords.zip.\n","       | Downloading package swadesh to /root/nltk_data...\n","       |   Unzipping corpora/swadesh.zip.\n","       | Downloading package timit to /root/nltk_data...\n","       |   Unzipping corpora/timit.zip.\n","       | Downloading package treebank to /root/nltk_data...\n","       |   Unzipping corpora/treebank.zip.\n","       | Downloading package toolbox to /root/nltk_data...\n","       |   Unzipping corpora/toolbox.zip.\n","       | Downloading package udhr to /root/nltk_data...\n","       |   Unzipping corpora/udhr.zip.\n","       | Downloading package udhr2 to /root/nltk_data...\n","       |   Unzipping corpora/udhr2.zip.\n","       | Downloading package unicode_samples to /root/nltk_data...\n","       |   Unzipping corpora/unicode_samples.zip.\n","       | Downloading package webtext to /root/nltk_data...\n","       |   Unzipping corpora/webtext.zip.\n","       | Downloading package wordnet to /root/nltk_data...\n","       |   Unzipping corpora/wordnet.zip.\n","       | Downloading package wordnet_ic to /root/nltk_data...\n","       |   Unzipping corpora/wordnet_ic.zip.\n","       | Downloading package words to /root/nltk_data...\n","       |   Unzipping corpora/words.zip.\n","       | Downloading package maxent_treebank_pos_tagger to\n","       |     /root/nltk_data...\n","       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","       | Downloading package maxent_ne_chunker to /root/nltk_data...\n","       |   Unzipping chunkers/maxent_ne_chunker.zip.\n","       | Downloading package universal_tagset to /root/nltk_data...\n","       |   Unzipping taggers/universal_tagset.zip.\n","       | Downloading package punkt to /root/nltk_data...\n","       |   Unzipping tokenizers/punkt.zip.\n","       | Downloading package book_grammars to /root/nltk_data...\n","       |   Unzipping grammars/book_grammars.zip.\n","       | Downloading package city_database to /root/nltk_data...\n","       |   Unzipping corpora/city_database.zip.\n","       | Downloading package tagsets to /root/nltk_data...\n","       |   Unzipping help/tagsets.zip.\n","       | Downloading package panlex_swadesh to /root/nltk_data...\n","       | Downloading package averaged_perceptron_tagger to\n","       |     /root/nltk_data...\n","       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","       | \n","     Done downloading collection book\n","\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> q\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"bob-QRgw5o-1"},"source":["Since there are some problems for translating the corpus from Scikit-Learn to LSI, we are now going to create 'natively' the corpus with Gensim."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"MNUqKTIA5o-1","executionInfo":{"status":"ok","timestamp":1652017557140,"user_tz":-120,"elapsed":764,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}}},"outputs":[],"source":["# import the gensim.corpora module to generate dictionary\n","from gensim import corpora\n","\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk import RegexpTokenizer\n","\n","import string\n","\n","def preprocess(words):\n","    tokenizer = RegexpTokenizer('[A-Z]\\w+')\n","    tokens = [w.lower() for w in tokenizer.tokenize(words)]\n","    stoplist = stopwords.words('english')\n","    tokens_stop = [w for w in tokens if w not in stoplist]\n","    punctuation = set(string.punctuation)\n","    tokens_clean = [w for w in tokens_stop if  w not in punctuation]\n","    return tokens_clean\n","\n","#words = preprocess(newsgroups_train.data)\n","#dictionary = corpora.Dictionary(newsgroups_train.data)\n","\n","texts = [preprocess(document) for document in newsgroups_train.data]\n","\n","dictionary = corpora.Dictionary(texts)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cui3-UUE5o-1","executionInfo":{"status":"ok","timestamp":1652017560292,"user_tz":-120,"elapsed":310,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"75d534e7-24f1-4727-8641-a15769f7ea1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary(10913 unique tokens: ['cel', 'ds', 'hi', 'nothing', 'prj']...)\n"]}],"source":["# You can save the dictionary\n","dictionary.save('newsgroup.dict.texts')\n","\n","print(dictionary)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"PQFbZxjO5o-2","executionInfo":{"status":"ok","timestamp":1652017562653,"user_tz":-120,"elapsed":298,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}}},"outputs":[],"source":["# Generate a list of docs, where each doc is a list of words\n","\n","docs = [preprocess(doc) for doc in newsgroups_train.data]"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Dr8ZNEY55o-2","executionInfo":{"status":"ok","timestamp":1652017564057,"user_tz":-120,"elapsed":329,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}}},"outputs":[],"source":["# import the gensim.corpora module to generate dictionary\n","from gensim import corpora\n","\n","dictionary = corpora.Dictionary(docs)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6SlGmyF5o-2","executionInfo":{"status":"ok","timestamp":1652017565252,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"5dc705ad-2101-4432-b591-c1a999bd011f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary(10913 unique tokens: ['cel', 'ds', 'hi', 'nothing', 'prj']...)\n"]}],"source":["# We can print the dictionary, it is a mappying of id and tokens\n","\n","print(dictionary)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"gVcDfT_r5o-3","executionInfo":{"status":"ok","timestamp":1652017566497,"user_tz":-120,"elapsed":2,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}}},"outputs":[],"source":["# construct the corpus representing each document as a bag-of-words (bow) vector\n","corpus = [dictionary.doc2bow(doc) for doc in docs]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"h2fNUxLi5o-3","executionInfo":{"status":"ok","timestamp":1652017567566,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}}},"outputs":[],"source":["from gensim.models import TfidfModel\n","\n","# calculate tfidf\n","tfidf_model = TfidfModel(corpus)\n","corpus_tfidf = tfidf_model[corpus]"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRckKm-M5o-3","executionInfo":{"status":"ok","timestamp":1652017569116,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"a3eeb828-0785-4799-cacd-813885392956"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 0.24093628445650234), (1, 0.5700978153855775), (2, 0.10438175896914427), (3, 0.1598114653031772), (4, 0.722808853369507), (5, 0.24093628445650234)]\n"]}],"source":["#print tf-idf of first document\n","print(corpus_tfidf[0])"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"-wNo9Bg65o-3","executionInfo":{"status":"ok","timestamp":1652017581286,"user_tz":-120,"elapsed":11004,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}}},"outputs":[],"source":["from gensim.models.ldamodel import LdaModel\n","\n","# train the lda model, choosing number of topics equal to 4, it takes a long time\n","\n","lda_model = LdaModel(corpus_tfidf, num_topics=4, passes=20, id2word=dictionary)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W66aB5bC5o-4","executionInfo":{"status":"ok","timestamp":1652017676775,"user_tz":-120,"elapsed":431,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"2e708f47-090c-47da-bde5-754e1d2af0e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0,\n","  '0.007*\"islam\" + 0.006*\"ns\" + 0.005*\"zoroastrians\" + 0.005*\"khomeini\" + 0.005*\"ssrt\" + 0.005*\"samaritan\" + 0.005*\"yayayay\" + 0.004*\"bull\" + 0.004*\"gerald\" + 0.004*\"septuagint\"'),\n"," (1,\n","  '0.010*\"baptist\" + 0.010*\"koresh\" + 0.009*\"bible\" + 0.008*\"plane\" + 0.007*\"bob\" + 0.005*\"shag\" + 0.005*\"scarlet\" + 0.004*\"tootsie\" + 0.004*\"kinda\" + 0.004*\"captain\"'),\n"," (2,\n","  '0.010*\"mary\" + 0.008*\"god\" + 0.007*\"moon\" + 0.007*\"western\" + 0.007*\"jeff\" + 0.006*\"joy\" + 0.006*\"jesus\" + 0.006*\"lucky\" + 0.006*\"joseph\" + 0.006*\"davidian\"'),\n"," (3,\n","  '0.010*\"whatever\" + 0.007*\"unix\" + 0.007*\"thanks\" + 0.006*\"phobos\" + 0.006*\"unfortunately\" + 0.006*\"martian\" + 0.005*\"hi\" + 0.005*\"russian\" + 0.005*\"rayshade\" + 0.004*\"would\"')]"]},"metadata":{},"execution_count":16}],"source":["# check the topics\n","lda_model.print_topics(4)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6DHsTuC5o-4","executionInfo":{"status":"ok","timestamp":1652017678721,"user_tz":-120,"elapsed":307,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"0fbe6644-813b-43c8-c02e-c92e8a7f3cf6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 0.084204), (1, 0.7040298), (2, 0.08284816), (3, 0.12891802)]\n"]}],"source":["# check the lsa vector for the first document\n","corpus_lda = lda_model[corpus_tfidf]\n","print(corpus_lda[0])"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ockc0gj5o-4","executionInfo":{"status":"ok","timestamp":1652017680116,"user_tz":-120,"elapsed":2,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"f4c99db6-5ed3-4044-99cc-f626b6b31578"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('lord', 1), ('god', 2)]\n"]}],"source":["#predict topics of a new doc\n","new_doc = \"God is love and God is the Lord\"\n","#transform into BOW space\n","bow_vector = dictionary.doc2bow(preprocess(new_doc))\n","print([(dictionary[id], count) for id, count in bow_vector])"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qoYUQUrq5o-5","executionInfo":{"status":"ok","timestamp":1652017682105,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"9d2191d9-78f0-493d-ba67-df8eb8506e06"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 0.06554373), (1, 0.06262062), (2, 0.8093011), (3, 0.06253459)]\n"]}],"source":["#transform into LDA space\n","lda_vector = lda_model[bow_vector]\n","print(lda_vector)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z4ZC8XEc5o-5","executionInfo":{"status":"ok","timestamp":1652017684748,"user_tz":-120,"elapsed":308,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"b52368be-ddb2-49af-c791-855c15a5fe5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.010*\"mary\" + 0.008*\"god\" + 0.007*\"moon\" + 0.007*\"western\" + 0.007*\"jeff\" + 0.006*\"joy\" + 0.006*\"jesus\" + 0.006*\"lucky\" + 0.006*\"joseph\" + 0.006*\"davidian\"\n"]}],"source":["# print the document's single most prominent LDA topic\n","print(lda_model.print_topic(max(lda_vector, key=lambda item: item[1])[0]))"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Opor0XeW5o-5","executionInfo":{"status":"ok","timestamp":1652017686929,"user_tz":-120,"elapsed":324,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"0a5410e8-f0a7-49bc-92ab-3cb6f83bd093"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 0.11036819), (1, 0.104191266), (2, 0.6814583), (3, 0.10398224)]\n","0.010*\"mary\" + 0.008*\"god\" + 0.007*\"moon\" + 0.007*\"western\" + 0.007*\"jeff\" + 0.006*\"joy\" + 0.006*\"jesus\" + 0.006*\"lucky\" + 0.006*\"joseph\" + 0.006*\"davidian\"\n"]}],"source":["lda_vector_tfidf = lda_model[tfidf_model[bow_vector]]\n","print(lda_vector_tfidf)\n","# print the document's single most prominent LDA topic\n","print(lda_model.print_topic(max(lda_vector_tfidf, key=lambda item: item[1])[0]))"]},{"cell_type":"markdown","metadata":{"id":"BQnawURp5o-6"},"source":["# Latent Semantic Indexing (LSI)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"IMMZhAPq5o-6","executionInfo":{"status":"ok","timestamp":1652017689287,"user_tz":-120,"elapsed":948,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}}},"outputs":[],"source":["from gensim.models.lsimodel import LsiModel\n","\n","#It takes a long time\n","\n","# train the lsi model, choosing number of topics equal to 20\n","\n","\n","lsi_model = LsiModel(corpus_tfidf, num_topics=4, id2word=dictionary)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxC_B3b-5o-6","executionInfo":{"status":"ok","timestamp":1652017690288,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"e83b3331-9490-45fa-c0f8-0739dccd5a08"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0,\n","  '-0.769*\"god\" + -0.346*\"jesus\" + -0.235*\"bible\" + -0.203*\"christian\" + -0.149*\"christians\" + -0.107*\"christ\" + -0.089*\"well\" + -0.085*\"koresh\" + -0.081*\"kent\" + -0.080*\"christianity\"'),\n"," (1,\n","  '-0.863*\"thanks\" + -0.255*\"please\" + -0.160*\"hello\" + -0.153*\"hi\" + 0.123*\"god\" + -0.111*\"sorry\" + -0.087*\"could\" + -0.075*\"windows\" + -0.066*\"jpeg\" + -0.063*\"gif\"'),\n"," (2,\n","  '-0.783*\"well\" + 0.229*\"god\" + -0.166*\"yes\" + 0.154*\"thanks\" + -0.132*\"ico\" + -0.131*\"tek\" + -0.129*\"beauchaine\" + -0.129*\"queens\" + -0.129*\"bronx\" + -0.128*\"manhattan\"'),\n"," (3,\n","  '-0.336*\"ico\" + 0.335*\"well\" + -0.334*\"tek\" + -0.329*\"beauchaine\" + -0.329*\"queens\" + -0.329*\"bronx\" + -0.326*\"manhattan\" + -0.306*\"com\" + -0.305*\"bob\" + -0.072*\"god\"')]"]},"metadata":{},"execution_count":23}],"source":["# check the topics\n","lsi_model.print_topics(4)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwJ9AU1d5o-6","executionInfo":{"status":"ok","timestamp":1652017692309,"user_tz":-120,"elapsed":334,"user":{"displayName":"Ángela Burgaleta Ledesma","userId":"01200761640961433987"}},"outputId":"7c2a5208-435f-4a06-f6e8-8a9e58b319a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 0.24093628445650234), (1, 0.5700978153855775), (2, 0.10438175896914427), (3, 0.1598114653031772), (4, 0.722808853369507), (5, 0.24093628445650234)]\n"]}],"source":["# check the lsi vector for the first document\n","print(corpus_tfidf[0])"]},{"cell_type":"markdown","metadata":{"id":"d78rXMvy5o-7"},"source":["# References"]},{"cell_type":"markdown","metadata":{"id":"4ECcI71F5o-7"},"source":["* [NLTK Book. Natural Language Processing with Python. Steven Bird, Ewan Klein, and Edward Loper. O'Reilly Media, 2009 ](http://www.nltk.org/book_1ed/)\n","* [NLTK Essentials, Nitin Hardeniya, Packt Publishing, 2015](http://proquest.safaribooksonline.com/search?q=NLTK%20Essentials)"]},{"cell_type":"markdown","metadata":{"id":"RIJHfxJ25o-7"},"source":["## Licence"]},{"cell_type":"markdown","metadata":{"id":"sgFxHhUA5o-7"},"source":["The notebook is freely licensed under under the [Creative Commons Attribution Share-Alike license](https://creativecommons.org/licenses/by/2.0/).  \n","\n","© Carlos A. Iglesias, Universidad Politécnica de Madrid."]}],"metadata":{"datacleaner":{"position":{"top":"50px"},"python":{"varRefreshCmd":"try:\n    print(_datacleaner.dataframe_metadata())\nexcept:\n    print([])"},"window_display":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"latex_envs":{"LaTeX_envs_menu_present":true,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"colab":{"name":"4_5_Semantic_Models.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}